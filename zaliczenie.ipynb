{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temat 2\n",
    "Przewidywanie wzięcia pożyczki.\n",
    "Michał Miłek, Katowice. GR. 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "from scipy import stats\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wykres_pareto(kolumna, df, percent, czy_wykres=True, figsizex=18, figsizey=8):\n",
    "    \"\"\"Zwraca listę kategorii kolumny 'kolumna' w dataframe 'df', \n",
    "        których skumulowana częstość wystąpienia sumuje się do 'percent'\n",
    "    Args:\n",
    "        kolumna:          nazwa kolumny do wyodrębnienia wariantów\n",
    "        df:               analizowany dataframe\n",
    "        percent:          testowana częstość skumulowana\n",
    "        czy_wykres=True:  przełącznik - czy rysować wykres\n",
    "        figsizex=18       szerokość wykresu\n",
    "        figsizey=18       wysokość wykresu     \n",
    "    Returns:\n",
    "        Lista kategorii danej kolumny, których skumulowana częstość wystąpienia sumuje się do założonego odsetka\n",
    "    \"\"\"\n",
    "    \n",
    "    df.loc[pd.isnull(df[kolumna] == '0'), kolumna] = np.nan\n",
    "    \n",
    "    Var_value_counts = df[kolumna].value_counts(dropna=True, sort=True).to_frame()\n",
    "    Var_value_counts.columns = ['Ilosc']\n",
    "    Var_value_counts[\"%_skumulowany\"] = Var_value_counts[\"Ilosc\"].cumsum()/Var_value_counts[\"Ilosc\"].sum()*100\n",
    "    Var_value_counts = Var_value_counts.loc[Var_value_counts['%_skumulowany'] <= percent*100]\n",
    "    \n",
    "    if czy_wykres:\n",
    "        fig, ax = plt.subplots(figsize=(figsizex, figsizey))\n",
    "        plt.xticks(rotation='vertical')\n",
    "        ax.bar(Var_value_counts.index, Var_value_counts[\"Ilosc\"], color=\"C0\")\n",
    "\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(Var_value_counts.index, Var_value_counts[\"%_skumulowany\"], color=\"C1\", marker=\"D\", ms=7)\n",
    "        ax2.yaxis.set_major_formatter(PercentFormatter())\n",
    "\n",
    "        ax.tick_params(axis=\"y\", colors=\"C0\")\n",
    "        ax2.tick_params(axis=\"y\", colors=\"C1\")\n",
    "\n",
    "        plt.show()\n",
    "    return Var_value_counts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wykres_analiza(dane, figsizex=18, figsizey=8):\n",
    "    dane = pd.DataFrame(dane)\n",
    "    \"\"\"Wyświetla wykres pudełkowy i histogram dla ciągu obserwacji\n",
    "    Args:\n",
    "        dane:        ciąg obserwacji do zaprezentowania na wykresie   \n",
    "        figsizex=18: szerokość wykresu\n",
    "        figsizey=18: wysokość wykresu     \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    sns.set(style=\"ticks\")\n",
    "\n",
    "    x = dane.dropna()\n",
    "\n",
    "    f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, \n",
    "                                        gridspec_kw={\"height_ratios\": (.15, .85)},figsize=(figsizex, figsizey))\n",
    "\n",
    "    sns.boxplot(x, ax=ax_box)\n",
    "    sns.distplot(x, ax=ax_hist)\n",
    "\n",
    "    ax_box.set(yticks=[])\n",
    "    sns.despine(ax=ax_hist)\n",
    "    sns.despine(ax=ax_box, left=True)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ładowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = \"https://raw.githubusercontent.com/saimadhu-polamuri/DataHakthon3X/master/dataSet/Train.csv\"\n",
    "#file = \"Train.csv\"\n",
    "\n",
    "encoding = \"ISO-8859-1\"\n",
    "\n",
    "df = pd.read_csv(file, encoding=encoding, index_col = 0)\n",
    "\n",
    "#  pominięcie zbędnej kolumny\n",
    "df = df.drop(columns=[\"LoggedIn\"])\n",
    "\n",
    "# podgląd danych\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przegląd zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opis zmiennych\n",
    "\n",
    "header = ['#Unik_wart','Typ', 'Puste', 'Zera']\n",
    "slownik = {column: [\n",
    "    len(pd.value_counts(df[column])), \n",
    "    df[column].dtype, \n",
    "    df[column].isna().sum(),\n",
    "    (df[column]==0).sum(),\n",
    "    ] for column in df.columns}\n",
    "kolumny = pd.DataFrame.from_dict(slownik, columns = header, orient='index')\n",
    "\n",
    "kolumny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapowanie i przekształcanie zmiennych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kodowanie zmiennych 0-1\n",
    "Gender_dummies = pd.get_dummies(df['Gender'], prefix='Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wybranie tylko 60% najczęsciej występujących miast, reszcie przypisanie \"Other\"\n",
    "df.loc[(~df['City'].isin (\n",
    "           wykres_pareto('City', df, 0.9))\n",
    "           ), 'City'] = 'Other'\n",
    "# kodowanie zmiennych 0-1\n",
    "City_dummies = pd.get_dummies(df['City'], prefix='City', dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Monthly_Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# przekształcenie zmiennej w transforamcji Boxa-Coxa\n",
    "Monthly_Income = stats.boxcox(df['Monthly_Income']+1, 0)\n",
    "\n",
    "# efekt przekształceń (z pominięciem wartości zerowych)\n",
    "wykres_analiza(Monthly_Income, 18, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna DOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamiana typu zmiennych zawierających datę na typ czasowy\n",
    "DOB = pd.to_datetime(df['DOB'], format='%d-%b-%y')\n",
    "# poprawa parsowania dat bez wieku\n",
    "DOB.loc[(DOB >= '2000-01-01') & (DOB <= '2068-12-31')] = DOB - pd.offsets.DateOffset(years=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna  Lead_Creation_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamiana typu zmiennych zawierających datę na typ czasowy\n",
    "Lead_Creation_Date = pd.to_datetime(df['Lead_Creation_Date'], format='%d-%b-%y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Loan_Amount_Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# zastąpienie brakujących danych\n",
    "imp = Imputer(missing_values= \"NaN\", strategy=\"mean\")\n",
    "imp.fit(df[[\"Loan_Amount_Applied\"]])\n",
    "Loan_Amount_Applied = imp.transform(df[[\"Loan_Amount_Applied\"]]).ravel()\n",
    "df[\"Loan_Amount_Applied\"] = Loan_Amount_Applied\n",
    "\n",
    "# przekształcenie zmiennej w transforamcji Boxa-Coxa\n",
    "Loan_Amount_Applied = stats.boxcox(Loan_Amount_Applied + 1, 0)\n",
    "\n",
    "# efekt przekształceń (z pominięciem wartości zerowych)\n",
    "wykres_analiza(Loan_Amount_Applied, 18, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Loan_Tenure_Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# zastąpienie brakujących danych\n",
    "imp = Imputer(missing_values= \"NaN\", strategy=\"mean\")\n",
    "imp.fit(df[[\"Loan_Tenure_Applied\"]])\n",
    "Loan_Tenure_Applied = imp.transform(df[[\"Loan_Tenure_Applied\"]]).ravel()\n",
    "df[\"Loan_Tenure_Applied\"] = Loan_Tenure_Applied\n",
    "\n",
    "# efekt przekształceń (z pominięciem wartości zerowych)\n",
    "wykres_analiza(Loan_Tenure_Applied, 18, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rata = df['Loan_Amount_Applied']/df['Loan_Tenure_Applied']/12\n",
    "Rata[(df['Loan_Amount_Applied'].isna())] = 0\n",
    "Rata[(df['Loan_Tenure_Applied'].isna())] = 0\n",
    "Rata[(df['Loan_Amount_Applied'] == 0)] = 0\n",
    "Rata[(df['Loan_Tenure_Applied'] == 0)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Existing_EMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# zastąpienie brakujących danych\n",
    "imp = Imputer(missing_values= \"NaN\", strategy=\"mean\")\n",
    "imp.fit(df[[\"Existing_EMI\"]])\n",
    "Existing_EMI = imp.transform(df[[\"Existing_EMI\"]]).ravel()\n",
    "\n",
    "Zdolnosc = df['Monthly_Income'] - Existing_EMI\n",
    "Zdolnosc[Zdolnosc < 0] = 0\n",
    "\n",
    "# przekształcenie zmiennej w transforamcji Boxa-Coxa\n",
    "Existing_EMI = stats.boxcox(Existing_EMI + 1, 0)\n",
    "\n",
    "# efekt przekształceń (z pominięciem wartości zerowych)\n",
    "wykres_analiza(Existing_EMI, 18, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Employer_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# potraktowanie wpisu nazwy pracodawcy = \"0\" jako braku danych\n",
    "df.loc[(df['Employer_Name'] == '0'), 'Employer_Name'] = np.nan\n",
    "\n",
    "# wybranie tylko 4% najczęsciej występujących miast, reszcie przypisanie \"Other\"\n",
    "df.loc[(~df['Employer_Name'].isin (\n",
    "           wykres_pareto('Employer_Name', df, 0.05))\n",
    "           ), 'Employer_Name'] = 'Other'\n",
    "# kodowanie zmiennych 0-1\n",
    "Employer_Name_dummies = pd.get_dummies(df['Employer_Name'], prefix='Employer_Name', dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Salary_Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wybranie tylko 80% najczęsciej występujących miast, reszcie przypisanie \"Other\"\n",
    "df.loc[(~df['Salary_Account'].isin (\n",
    "           wykres_pareto('Salary_Account', df, 0.9))\n",
    "           ), 'Salary_Account'] = 'Other'\n",
    "# kodowanie zmiennych 0-1\n",
    "Salary_Account_dummies = pd.get_dummies(df['Salary_Account'], prefix='Salary_Account', dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Mobile_Verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kodowanie zmiennych 0-1\n",
    "Mobile_Verified_dummies = pd.get_dummies(df['Mobile_Verified'], prefix='Mobile_Verified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Var5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przypisanie zmiennej\n",
    "Var5 = df['Var5']\n",
    "\n",
    "# efekt przekształceń (z pominięciem wartości zerowych)\n",
    "wykres_analiza(Var5, 18, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wybranie tylko 90% najczęsciej występujących wartości, reszcie przypisanie \"Other\"\n",
    "df.loc[(~df['Var1'].isin (\n",
    "           wykres_pareto('Var1', df, 0.9))\n",
    "           ), 'Var1'] = 'Other'\n",
    "# kodowanie zmiennych 0-1\n",
    "Var1_dummies = pd.get_dummies(df['Var1'], prefix='Var1', dummy_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Loan_Amount_Submitted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uzupełnienie braków na podstawie zmiennej Loan_Amount_Applied\n",
    "df.loc[(df['Loan_Amount_Submitted'].isna()), 'Loan_Amount_Submitted'] = 0 #df['Loan_Amount_Applied']\n",
    "\n",
    "# przypisanie zmiennej\n",
    "Loan_Amount_Submitted = df['Loan_Amount_Submitted']\n",
    "\n",
    "#Loan_Amount_Submitted[df['Loan_Amount_Submitted'].isna()] = 0\n",
    "\n",
    "# przekształcenie zmiennej w transforamcji Boxa-Coxa\n",
    "Loan_Amount_Submitted = stats.boxcox(Loan_Amount_Submitted + 1, 0)\n",
    "\n",
    "# efekt przekształceń\n",
    "wykres_analiza(Loan_Amount_Submitted, 18, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Loan_Tenure_Submitted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uzupełnienie braków na podstawie zmiennej Loan_Amount_Applied\n",
    "df.loc[(df['Loan_Tenure_Submitted'].isna()), 'Loan_Tenure_Submitted'] = 0 #df['Loan_Tenure_Applied']\n",
    "#Loan_Tenure_Submitted[df['Loan_Tenure_Submitted'].isna()] = 0\n",
    "\n",
    "# przypisanie zmiennej\n",
    "Loan_Tenure_Submitted = df['Loan_Tenure_Submitted']\n",
    "\n",
    "# przekształcenie zmiennej w transforamcji Boxa-Coxa\n",
    "Loan_Tenure_Submitted = stats.boxcox(Loan_Amount_Submitted + 1, 0)\n",
    "\n",
    "# efekt przekształceń\n",
    "wykres_analiza(Loan_Tenure_Submitted, 18, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Interest_Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przypisanie zmiennej\n",
    "Interest_Rate = df['Interest_Rate']\n",
    "\n",
    "# uzupełnienie braków na podstawie zmiennej Loan_Amount_Applied\n",
    "#df.loc[(df['Interest_Rate'].isna()), 'Interest_Rate'] = df['Interest_Rate']\n",
    "Interest_Rate[df['Interest_Rate'].isna()] = 0\n",
    "\n",
    "# przekształcenie zmiennej w transforamcji Boxa-Coxa\n",
    "Interest_Rate = stats.boxcox(Interest_Rate + 1, 0)\n",
    "\n",
    "# efekt przekształceń\n",
    "wykres_analiza(Interest_Rate, 18, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Processing_Fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przypisanie zmiennej\n",
    "Processing_Fee = df['Processing_Fee']\n",
    "\n",
    "# uzupełnienie braków na podstawie zmiennej Loan_Amount_Applied\n",
    "#df.loc[(df['Processing_Fee'].isna()), 'Processing_Fee'] = df['Processing_Fee']\n",
    "Processing_Fee[df['Processing_Fee'].isna()] = 0\n",
    "\n",
    "# przekształcenie zmiennej w transforamcji Boxa-Coxa\n",
    "Processing_Fee = stats.boxcox(Processing_Fee + 1, 0)\n",
    "\n",
    "# efekt przekształceń\n",
    "wykres_analiza(Processing_Fee, 18, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna EMI_Loan_Submitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przypisanie zmiennej\n",
    "EMI_Loan_Submitted = df['EMI_Loan_Submitted']\n",
    "\n",
    "# uzupełnienie braków na podstawie zmiennej EMI_Loan_Submitted\n",
    "#df.loc[(df['EMI_Loan_Submitted'].isna()), 'EMI_Loan_Submitted'] = df['EMI_Loan_Submitted']\n",
    "EMI_Loan_Submitted[df['EMI_Loan_Submitted'].isna()] = 0\n",
    "\n",
    "# przekształcenie zmiennej w transforamcji Boxa-Coxa\n",
    "EMI_Loan_Submitted = stats.boxcox(EMI_Loan_Submitted + 1, 0)\n",
    "\n",
    "# efekt przekształceń\n",
    "wykres_analiza(EMI_Loan_Submitted, 18, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Filled_Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kodowanie zmiennych 0-1\n",
    "Filled_Form_dummies = pd.get_dummies(df['Filled_Form'], prefix='Filled_Form')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Device_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kodowanie zmiennych 0-1\n",
    "Device_Type_dummies = pd.get_dummies(df['Device_Type'], prefix='Device_Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kodowanie zmiennych 0-1\n",
    "Var2_dummies = pd.get_dummies(df['Var2'], prefix='Var2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zmienna Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kodowanie zmiennych 0-1\n",
    "Source_dummies = pd.get_dummies(df['Source'], prefix='Source')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zmienna Var4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kodowanie zmiennych 0-1\n",
    "Var4_dummies = pd.get_dummies(df['Var4'], prefix='Var4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zmienna Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obliczenie wieku klienta w momencie złożenia wniosku (w dniach)\n",
    "Age = (((Lead_Creation_Date - DOB)/ np.timedelta64(1, 'D')).astype(int))\n",
    "\n",
    "# przekształcenie zmiennej w transforamcji Boxa-Coxa\n",
    "Age = stats.boxcox(Age + 1, 0)\n",
    "\n",
    "wykres_analiza(Age, 18, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Złożenie przekształceń i pominięcie części zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([\n",
    "    df['Disbursed'],\n",
    "    Gender_dummies,\n",
    "    City_dummies,\n",
    "    Employer_Name_dummies,\n",
    "    Salary_Account_dummies,\n",
    "    Mobile_Verified_dummies,\n",
    "    Var5,\n",
    "    Var1_dummies,\n",
    "    Filled_Form_dummies,\n",
    "    Device_Type_dummies,\n",
    "    Var2_dummies,\n",
    "    Source_dummies,\n",
    "    Var4_dummies\n",
    "    ], axis=1)\n",
    "\n",
    "df1['Monthly_Income'] = Monthly_Income\n",
    "df1['Loan_Amount_Applied'] = Loan_Amount_Applied\n",
    "df1['Loan_Tenure_Applied'] = Loan_Tenure_Applied\n",
    "df1['Existing_EMI'] = Existing_EMI\n",
    "df1['Loan_Amount_Submitted'] = Loan_Amount_Submitted\n",
    "df1['Loan_Tenure_Submitted'] = Loan_Tenure_Submitted\n",
    "df1['Interest_Rate'] = Interest_Rate\n",
    "df1['Processing_Fee'] = Processing_Fee\n",
    "df1['EMI_Loan_Submitted'] = EMI_Loan_Submitted\n",
    "df1['Rata'] = Rata\n",
    "df1['Zdolnosc'] = Zdolnosc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podgląd danych po przekształceniach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opis zmiennych\n",
    "\n",
    "header = ['#Unik_wart','Typ', 'Puste', 'Zera', 'Minimum']\n",
    "slownik = {column: [\n",
    "    len(pd.value_counts(df1[column])), \n",
    "    df1[column].dtype, \n",
    "    df1[column].isna().sum(),\n",
    "    (df1[column]==0).sum(),\n",
    "    np.min(df1[column]) \n",
    "    ] for column in df1.columns}\n",
    "kolumny = pd.DataFrame.from_dict(slownik, columns = header, orient='index')\n",
    "\n",
    "kolumny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poszukiwanie najlepszego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(columns=[\"Disbursed\"])\n",
    "y = df1.Disbursed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# etykiety porównywanych modeli\n",
    "names = np.array([\"Naiwny Bayes\", \"Drzewo decyzyjne\", \"Regresja logistyczna\", \"SVM\",\n",
    "                 \"BaggingClassifier_tree\", \"BaggingClassifier_bayes\", \"RandomForest\", \"XGBoost\"])\n",
    "\n",
    "# definicja pipeline\n",
    "models = [[(\"model\", MultinomialNB())],\n",
    "         [(\"model\", DecisionTreeClassifier())],\n",
    "         [(\"scaler\", StandardScaler()), (\"model\", LogisticRegression())],\n",
    "         [(\"scaler\", StandardScaler()), (\"model\", SVC())],\n",
    "         [(\"model\", BaggingClassifier(base_estimator = DecisionTreeClassifier()))],\n",
    "         [(\"model\", BaggingClassifier(base_estimator = MultinomialNB()))],\n",
    "         [(\"scaler\", StandardScaler()), (\"model\", RandomForestClassifier())],\n",
    "         [(\"model\", xgb.XGBClassifier(\n",
    "                booster = 'gbtree', \n",
    "                objective = 'binary:logistic', \n",
    "                max_depth = 11, \n",
    "                eval_metric = 'auc',\n",
    "                eta = 0.01, \n",
    "                silent = 1, \n",
    "                nthread = 4,\n",
    "                colsample_bytree = 0.99, \n",
    "                scale_pos_weight = 1,\n",
    "                min_child_weight = 2, \n",
    "                max_delta_step = 3,\n",
    "                n_jobs = 3,\n",
    "                subsample = 0.99\n",
    "         ))]\n",
    "         ]\n",
    "\n",
    "# warianty testowanych parametrów\n",
    "param_grids = [{\"model__alpha\": [0.01, 1, 1000], \"model__fit_prior\": [False, True]},\n",
    "               {\"model__criterion\": [\"gini\", \"entropy\"], \"model__min_samples_split\": [2, 10, 20], \"model__max_depth\": [None, 2, 10, 100, 200, 1000]}, \n",
    "               {\"model__penalty\": [\"l1\", \"l2\"], \"model__C\": [0.001, 1, 100]},\n",
    "              [{\"model__kernel\": [\"rbf\"], \"model__gamma\": [0.1, 1, 10]},\n",
    "              {\"model__kernel\": [\"poly\"], \"model__degree\": [3, 4, 5]}],\n",
    "               {\"model__n_estimators\" : [10, 100, 1000], \"model__max_features\": [0.1, 0.5, 0.8, 1.0]},\n",
    "               {\"model__n_estimators\" : [10, 100, 1000], \"model__max_features\": [0.5, 0.8, 1.0]},\n",
    "               {\"model__n_estimators\" : [10, 100, 1000], \"model__min_samples_leaf\" : [2, 10, 20, 50]},\n",
    "               {\"model__n_estimators\" : [10, 100, 1000]}\n",
    "              ]\n",
    "\n",
    "# służy do włączania/wyłączania odpowiedniego modelu z obliczeń \n",
    "uses = np.array([True, True, True, True, True, True, True, True])\n",
    "\n",
    "# testowanie poprawności definicji modeli\n",
    "if len(names) != len(models) or len(models) != len(param_grids) or len(param_grids) != len(uses):\n",
    "    print(f\"len(names): {len(names)}\")\n",
    "    print(f\"len(models): {len(models)}\")\n",
    "    print(f\"len(param_grids): {len(param_grids)}\")\n",
    "    print(f\"len(uses): {len(uses)}\")\n",
    "    raise ValueError(\"Listy nie mają tej samej długości!\")\n",
    "\n",
    "# uczenie/estymacja parametrów rozważanych modeli i wybór najlepszego w danej klasie    \n",
    "best_models = []\n",
    "\n",
    "for use, name, pipe, params in zip(uses, names, models, param_grids):\n",
    "    if not use:\n",
    "        continue\n",
    "    print(f\"Estymacja modelu: {name}\")\n",
    "    pipeline = Pipeline(pipe)\n",
    "    gs = GridSearchCV(estimator=pipeline, param_grid=params, n_jobs=3, scoring = 'roc_auc', cv=5)\n",
    "    gs.fit(X_train, y_train)\n",
    "    for mean, std, param, fit_time, score_time in zip(gs.cv_results_[\"mean_test_score\"],\n",
    "                                gs.cv_results_[\"std_test_score\"],\n",
    "                                gs.cv_results_[\"params\"],\n",
    "                                gs.cv_results_[\"mean_fit_time\"],\n",
    "                                gs.cv_results_[\"mean_score_time\"]):\n",
    "        print(f\"{param}:\\n mean: {np.round(mean, 4)}, std: {np.round(std,4)},\\n fit_time: {np.round(fit_time, 4)}, score_time: {np.round(score_time,4)}\\n\")\n",
    "    best_models.append(gs.best_estimator_)\n",
    "\n",
    "best_models = np.array(best_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porównanie najlepszych modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykorzystano następujące miary oceny jakości modeli. \n",
    "# Ostatnia wartość wskazuje liczbę klientów, którym przyporzadkowano wartość 1 prognozowanej zmiennej\n",
    "\n",
    "header = ['accuracy_score', 'f1_score', 'recall_score', 'recall_score:1', 'roc_auc_score', 'ile1']\n",
    "slownik = {name: [\n",
    "    np.round(accuracy_score(best_model.predict(X_test), y_test), 5),\n",
    "    np.round(f1_score(best_model.predict(X_test), y_test, average='weighted'), 5),\n",
    "    np.round(recall_score(best_model.predict(X_test), y_test, average='weighted'), 5),\n",
    "    np.round(recall_score(best_model.predict(X_test), y_test, average=None)[1], 5),\n",
    "    np.round(roc_auc_score(best_model.predict(X_test), y_test), 5) if best_model.predict(X_test).sum() > 0 else 0,\n",
    "    best_model.predict(X_test).sum()\n",
    "    \n",
    "    ] for name, best_model in zip(names[uses], best_models)}\n",
    "\n",
    "wyniki = pd.DataFrame.from_dict(slownik, columns = header, orient='index')\n",
    "wyniki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako miarę jakości dopasowania danych z modelu do danych rzeczywistych oraz porównania między modelami, wykorzystano obszar pod krzywą operacyjno-charakterystyczną: roc-auc, ze względu na znaczną asymetrię w liczebności próby. Najlepszym modelem jest te, którego wartość roc_auc_score jest najwyższa. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
